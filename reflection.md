I used GitHub Copilot to help generate the structure of four main functions `load_data()`, `clean_column_names()`, `handle_missing_values()`, and `remove_invalid_rows()`. I used Copilot by writing function signatures with type hints and docstrings that described what each function should do. For example, I wrote a comment "Load sales data from CSV file" and Copilot suggested the pandas read_csv implementation. I also used Copilot to help organize the data validation logic.

I made several changes to Copilot's suggestions. First, I simplified the docstrings that Copilot initially generated. I condensed these to single line summaries for clarity. I also reorganized the comment structure to be more concise, focusing on "what" and "why" rather than explanations. Finally, I customized variable names and made the removal tracking logic clearer by tracking row counts at each step instead of Copilot's original code.

Working with Copilot taught me several important lessons about data cleaning and AI assisted development. One strength of Copilot is that it quickly suggests code and common patternsusing pandas for CSV operations. A major limitation is that it doesn't understand your specific file structure or data format. For example, when I first ran the script Copilot had suggested generic file paths that did not work with my MAC.

Overall, Copilot was most effective as a starting point for structure and common patterns, but required review and modification to handle the specific requirements of this dataset and project.
